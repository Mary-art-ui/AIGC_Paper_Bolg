 [Retrieval augmented generation (rag) and beyond: A comprehensive survey on how to make your llms use external data more wisely](https://arxiv.org/abs/2409.14924)

[被引用次数：123](https://scholar.google.com/scholar?cites=1367863433047780472&as_sdt=80005&sciodt=0,11&hl=zh-CN)

Zhao S, Yang Y, Wang Z, et al. Retrieval augmented generation (rag) and beyond: A comprehensive survey on how to make your llms use external data more wisely[J]. arXiv preprint arXiv:2409.14924, 2024.

**Microsoft Research Asia**

------

## 1) 读懂这篇论文前，你要先补齐哪些“地基”知识？

这篇综述的核心观点是：**“不要把所有问题都当成 同一种 RAG 问题”**。作者把数据增强 LLM 的问题 按“外部数据 + 推理”分成四档（L1–L4），并给出每档更合适的技术路线（见摘要与结论对贡献的概述 、以及 Fig.1/2 的分层定义 ）。因此你需要的基础知识也可以按这条主线来准备。

### A. 你得先知道：LLM 为什么要“用外部数据”

- **幻觉（hallucination）**：LLM 会编造看似合理但错误的事实；外部数据可减少幻觉、提升可控性与可解释性（摘要 ）。
- **时效性与私有/领域知识**：训练语料滞后、覆盖不全，尤其是用户私有数据；RAG 或微调能把“最新/私有/专业”注入系统（引言 ）。

### B. RAG 系统最基本的组成与常见坑

你至少要熟悉一个最小 RAG 的流程：
**Query → 检索（retrieval）→（可选）重排（rerank）→ 拼接上下文（context）→ LLM 生成（generation）**。

用一个简化流程图表示：

```mermaid
flowchart LR
Q[用户问题 Q] --> R[检索 Retriever]
R --> K[Top-k 文段/证据]
K --> RR[重排/过滤 Reranker]
RR --> C[组装上下文 Context]
C --> LLM[LLM 生成]
LLM --> A[回答 A]
```

并且要理解一个“核心难点”：**问句和文档怎么对齐（alignment）**。论文把 Query-Document Alignment 讲得很关键，并指出三类对齐方式（Fig.3 相关文字说明 ）：

1. **传统对齐**：query 和 doc 映射到同一个向量空间（稠密检索、**双塔**等）。
2. **文档域对齐**：先生成“假想答案”再去检索（如 HyDE）。
3. **查询域对齐**：为文档生成“合成问题”，把 doc 映射到 query 空间再检索。

### C. “四类问题分层”背后的推理难度（这篇论文的主轴）

作者把问题分成四档（Fig.1/2）：

- **L1 显式事实**：答案就写在某段外部文本里；主要难点是“定位那一段”。
- **L2 隐式事实**：需要把多个片段事实拼起来/做简单推断。
- **L3 可解释理由**：外部数据提供明确“流程/规则/指南”，LLM 要按其执行（如医疗指南、客服流程）。
- **L4 隐含理由**：规则不明写、靠大量历史案例/隐性经验“悟出来”，最难。

你读论文时要能分清：一个任务到底是“找事实”，还是“按规则做决策”，还是“从案例里抽象方法”。

### D. 基本评测/数据集常识（知道即可，不必死记）

Table 1 把常见 QA/多跳/事实核查等数据集按 L1/L2 分层（并标注是否多引用）。
你需要的不是背列表，而是理解：

- **L1 多是单段可答**（如 NQ、SQuAD 等）；
- **L2 多是 multi-hop**（如 HotPotQA、2WikiMultiHopQA 等）。

------

## 2) 论文通俗解读：它到底讲了什么？为什么“Beyond RAG”？

### 2.1 论文的贡献用一句话概括

作者认为数据增强 LLM **没有一招鲜**，关键在于先识别“问题属于哪一档”，再选对应技术；他们提出四级分类（L1–L4），总结每级挑战、数据集与最有效方法（摘要 ，并在 Fig.1/2 做了直观分层 ）。

### 2.2 先看 Fig.1 + Fig.2：四级问题“关注点”逐级变化

- L1/L2：关注点是 **facts（事实）**，只是从“直接可取”变为“需要拼接/推断”。
- L3/L4：关注点转为 **rationales（理由/方法）**，从“外部明示的规则/流程”变为“外部数据里隐含的专家经验/解题策略”。

你可以把它理解为：

> 前两级是“查资料 + 归纳”，后两级是“学做事 + 学思路”。

### 2.3 关键中的关键：Fig.5 给的“分级选型指南”

作者在结论里把各级推荐技术讲得很直白（并指向 Fig.5 总结 ；Fig.5 caption ）：

- **静态常识类**：直接用通用 LLM + **Chain-of-Thought** 就可能够用。
- **L1 显式事实**：主要难点是“把事实定位到数据库/文档位置”，所以 **基础 RAG** 最合适。
- **L2 隐式事实**：要拼多个事实，推荐 **迭代式 RAG**、以及在 **图/树结构** 上做 RAG 来“边找边连”。
  - 当需要大规模“数据联结”时，**Text-to-SQL** 变得关键：把检索交给数据库工具做。
- **L3 可解释理由**：重点是让 LLM **服从外部规则/流程**，所以强调 **prompt tuning + CoT prompting**。
  - Fig.4 给了“理由型查询”的直观示例（如医疗指南/客服流程），并在段落里解释了为什么它本质上是“按外部推理脚本执行”。
- **L4 隐含理由**：最难，要 LLM 从大量数据里“自己总结解决问题的方法”，作者点名 **offline learning、in-context learning、fine-tuning** 是关键路线。

我建议你把 Fig.5 当成这篇综述的“总地图”：**先分级 → 再选法 → 再做系统工程**。

### 2.4 “Beyond RAG”：不仅是把文档塞进上下文，还有三种注入外部知识的路线（Fig.6）

作者把“怎么把领域数据用起来”分成三类（Fig.6 caption ，并在结论解释利弊 ）：

1. **Context 注入**：检索出一部分数据作为上下文喂给 LLM
   - 优点：更可解释、更稳定；
   - 局限：上下文窗口有限、且可能出现“中部信息丢失”等问题。
2. **Small model 注入**：先训练一个小模型吸收领域数据，再由它来“指导”往 LLM 输入哪些外部信息
   - 优点：训练更快，可吸收更多数据；
   - 局限：效果受小模型能力上限影响。
3. **Fine-tuning 注入**：用领域知识直接微调大模型，变成“领域专家模型”
   - 优点：能充分利用大模型能力；
   - 风险：数据设计不当会带来更错误输出、遗忘旧知识、覆盖不到未见任务等。

------

## 3) 重要术语清单：用通俗中文把它们讲明白

下面这些词，基本就是你读完整篇论文会反复遇到的“关键词”。

### 分层与任务定义类

- **Data-augmented LLM application（数据增强 LLM 应用）**：用外部数据 (D) 帮助 LLM 把 Query (Q) 映射到 Answer (A) 的系统（论文用 (f: Q \xrightarrow{D} A) 表示）
- **L1 Explicit Fact Queries（显式事实查询）**：答案能从某个文段直接取出来，推理极少。
- **L2 Implicit Fact Queries（隐式事实查询）**：需要把多个文段里的事实拼起来，或做简单常识/逻辑推断。
- **L3 Interpretable Rationale Queries（可解释理由查询）**：外部数据给了明确规则/流程/指南，LLM 的任务是“理解并遵循”。
- **L4 Hidden Rationale Queries（隐含理由查询）**：外部数据不直接写规则，而是藏在大量案例/经验里，需要模型“抽象出方法”。

### 检索与对齐类（RAG 的“工程核心”）

- **Retriever（检索器）**：从外部库里找 Top-k 相关片段。
- **Query-Document Alignment（查询-文档对齐）**：让“用户怎么问”和“文档怎么写”匹配上。论文强调三种对齐路径（传统/文档域/查询域）
- **Query Rewriting（查询改写）**：用户术语不准/描述模糊时，把问题改写得更利于检索（论文在 Fig.3 周边讨论中提到这一点 ）。
- **Re-ranking（重排）**：先粗检索，再精排序/过滤，把真正有用证据放前面（Fig.3 后续段落提到“retrieve top k 后要 filter and reorder” ）。

### 推理与注入外部知识类（“Beyond RAG” 的重点）

- **Chain-of-Thought（CoT）**：让模型把推理过程写出来，常用于复杂推理或让模型更稳（结论里把它作为“静态常识类”可用方案之一 ）。
- **Iterative RAG（迭代式 RAG）**：一轮检索不够就“检索—生成—再检索”，适配 L2 多跳拼接（结论推荐 ）。
- **Graph/Tree RAG（图/树结构 RAG）**：把事实/实体/证据组织成图或树，边检索边把多条证据连接起来（同上 ）。
- **Text-to-SQL**：把自然语言问题转成 SQL，让数据库来做复杂联结与过滤（结论指出当“extensive data linkage”需要时它很关键 ）。
- **Prompt tuning / Prompt optimization（提示词调优）**：为 L3 这类“按外部规则执行”的任务，设计/学习更合适的提示，让模型更听话（结论强调 ）。
- **In-context learning（ICL，上下文学习）**：不训练参数，只在上下文给示例/规则让模型临场学；被作者视为应对更难任务的重要途径之一（L4 相关结论 ）。
- **Fine-tuning（微调）**：训练模型参数以“吸收领域知识/能力”；强但贵且有遗忘与误导风险（结论 ）。
- **三种领域知识注入方式（Fig.6）**：Context / Small model / Fine-tuning 三路线（Fig.6 caption ）。

------

